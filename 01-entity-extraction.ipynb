{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/ML-engineering/blob/master/01-entity-extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46fa37fd-e892-4504-ad32-edabb4760596",
      "metadata": {
        "id": "46fa37fd-e892-4504-ad32-edabb4760596"
      },
      "source": [
        "# Entity Extraction with Claude\n",
        "\n",
        "> *This notebook should work well with the **`Python 3`** kernel in SageMaker Studio*\n",
        "\n",
        "### Choosing an approach\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "### Context\n",
        "Entity extraction is an NLP technique that allows us to automatically extract specific data from naturally written text, such as news, emails, books, etc.\n",
        "That data can then later be saved to a database, used for lookup or any other type of processing.\n",
        "\n",
        "Classic entity extraction programs usually limit you to pre-defined classes, such as name, address, price, etc. or require you to provide many examples of types of entities you are interested in.\n",
        "By using a LLM for entity extraction in most cases you are only required to specify what you need to extract in natural language. This gives you flexibility and accuracy in your queries while saving time by removing necessity of data labeling.\n",
        "\n",
        "In addition, LLM entity extraction can be used to help you assemble a dataset to later create a customised solution for your use case, such as [Amazon Comprehend custom entity](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html) recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "373675b6-cdc4-437e-83b5-7d897516b8fc",
      "metadata": {
        "id": "373675b6-cdc4-437e-83b5-7d897516b8fc"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dcc1624-19bf-4a3d-857a-89776dc74c3c",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "3dcc1624-19bf-4a3d-857a-89776dc74c3c"
      },
      "outputs": [],
      "source": [
        "# %pip install -U langchain-aws=='0.1.17'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ef0441-b424-403e-9394-d81b64e8332b",
      "metadata": {
        "tags": [],
        "id": "d8ef0441-b424-403e-9394-d81b64e8332b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import boto3\n",
        "import botocore\n",
        "\n",
        "boto3_bedrock = boto3.client('bedrock-runtime')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code importe plusieurs modules Python et initialise un client Boto3 pour interagir avec Amazon Bedrock. Voici une explication détaillée :\n",
        "\n",
        "1. Les importations :\n",
        "   - `json` : pour travailler avec des données JSON\n",
        "   - `os` et `sys` : pour interagir avec le système d'exploitation\n",
        "   - `boto3` et `botocore` : pour interagir avec les services AWS\n",
        "\n",
        "2. Initialisation du client Bedrock :\n",
        "   ```python\n",
        "   boto3_bedrock = boto3.client('bedrock-runtime')\n",
        "   ```\n",
        "   Cette ligne crée un client Boto3 spécifiquement pour le service Amazon Bedrock Runtime.\n",
        "\n",
        "Ce code est le début d'un script qui va interagir avec Amazon Bedrock, probablement pour utiliser des modèles d'IA ou effectuer des tâches liées à l'apprentissage automatique.\n",
        "\n",
        "Il est important de noter que pour que ce code fonctionne correctement, vous devez avoir configuré vos identifiants AWS correctement, soit via des variables d'environnement, soit via un fichier de configuration AWS."
      ],
      "metadata": {
        "id": "ANG9VDFFAARJ"
      },
      "id": "ANG9VDFFAARJ"
    },
    {
      "cell_type": "markdown",
      "id": "1fb9074b-d72e-4419-9165-421414d28f4b",
      "metadata": {
        "id": "1fb9074b-d72e-4419-9165-421414d28f4b"
      },
      "source": [
        "## Configure langchain\n",
        "\n",
        "We begin with instantiating the LLM. Here we are using Anthropic Claude v3 for text generation.\n",
        "\n",
        "Note: It is possible to choose other models available with Bedrock. For example, you can replace the `model_id` as follows to change the model to Titan Text Premier. Make sure your account has access to the model you want to try out before trying this!\n",
        "\n",
        "`llm = ChatBedrock(model_id=\"amazon.titan-text-premier-v1:0\")`\n",
        "\n",
        "Check [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) for Available text generation model Ids under Amazon Bedrock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621790c0-332a-4bab-bf81-967a63cb52fa",
      "metadata": {
        "tags": [],
        "id": "621790c0-332a-4bab-bf81-967a63cb52fa"
      },
      "outputs": [],
      "source": [
        "from langchain_aws import ChatBedrock\n",
        "\n",
        "llm = ChatBedrock(\n",
        "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    model_kwargs={\n",
        "        \"max_tokens\": 200,\n",
        "        \"temperature\": 0, # Using 0 to get reproducible results\n",
        "        \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question implicite dans ce code concerne l'utilisation de la bibliothèque `langchain_aws` et plus particulièrement la classe `ChatBedrock` pour interagir avec le modèle Claude 3 d'Anthropic via AWS Bedrock.\n",
        "\n",
        "Voici une explication du code :\n",
        "\n",
        "```markdown\n",
        "from langchain_aws import ChatBedrock\n",
        "\n",
        "llm = ChatBedrock(\n",
        "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    model_kwargs={\n",
        "        \"max_tokens\": 200,\n",
        "        \"temperature\": 0,\n",
        "        \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "Ce code initialise un objet `llm` de type `ChatBedrock` qui permet d'interagir avec le modèle de langage Claude 3 d'Anthropic via AWS Bedrock. Voici les détails des paramètres utilisés :\n",
        "\n",
        "1. `model_id` : Spécifie la version exacte du modèle Claude 3 à utiliser.\n",
        "2. `model_kwargs` : Un dictionnaire contenant des paramètres supplémentaires pour le modèle :\n",
        "   - `max_tokens` : Limite la réponse à 200 tokens maximum.\n",
        "   - `temperature` : Réglée à 0 pour obtenir des résultats reproductibles (moins de créativité/variabilité).\n",
        "   - `stop_sequences` : Indique au modèle d'arrêter la génération lorsqu'il rencontre la séquence \"\\n\\nHuman:\".\n",
        "\n",
        "Ce code configure essentiellement un client pour interagir avec le modèle Claude 3 via AWS Bedrock, en définissant des paramètres spécifiques pour contrôler la génération de texte."
      ],
      "metadata": {
        "id": "_ZmFbwgcASGh"
      },
      "id": "_ZmFbwgcASGh"
    },
    {
      "cell_type": "markdown",
      "id": "5f85e961-3530-4bf4-ac28-12611965d408",
      "metadata": {
        "id": "5f85e961-3530-4bf4-ac28-12611965d408"
      },
      "source": [
        "## Entity Extraction\n",
        "Now that we have our LLM initialised, we can start extracting entities.\n",
        "\n",
        "For this exercise we will pretend to be an online bookstore that receives questions and orders by email.\n",
        "Our task would be to extract relevant information from the email to process the order.\n",
        "\n",
        "Let's begin by taking a look at the sample email:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b958f4c7-0ded-4537-9939-d1623337317f",
      "metadata": {
        "tags": [],
        "id": "b958f4c7-0ded-4537-9939-d1623337317f"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "emails_dir = Path(\".\") / \"emails\"\n",
        "with open(emails_dir / \"00_treasure_island.txt\") as f:\n",
        "    book_question_email = f.read()\n",
        "\n",
        "print(book_question_email)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Il importe le module `Path` de la bibliothèque `pathlib`.\n",
        "2. Il crée un chemin vers un répertoire nommé \"emails\" dans le répertoire courant.\n",
        "3. Il ouvre un fichier spécifique nommé \"00_treasure_island.txt\" dans ce répertoire.\n",
        "4. Il lit le contenu du fichier.\n",
        "5. Enfin, il imprime le contenu du fichier.\n",
        "\n",
        "Voici une explication plus détaillée :\n",
        "\n",
        "```markdown\n",
        "from pathlib import Path\n",
        "```\n",
        "Cette ligne importe la classe `Path` du module `pathlib`, qui fournit une interface orientée objet pour travailler avec les chemins de fichiers.\n",
        "\n",
        "```markdown\n",
        "emails_dir = Path(\".\") / \"emails\"\n",
        "```\n",
        "Cette ligne crée un objet `Path` représentant le répertoire \"emails\" dans le répertoire courant (représenté par \".\").\n",
        "\n",
        "```markdown\n",
        "with open(emails_dir / \"00_treasure_island.txt\") as f:\n",
        "    book_question_email = f.read()\n",
        "```\n",
        "Ce bloc ouvre le fichier \"00_treasure_island.txt\" dans le répertoire \"emails\", lit son contenu et le stocke dans la variable `book_question_email`.\n",
        "\n",
        "```markdown\n",
        "print(book_question_email)\n",
        "```\n",
        "Cette dernière ligne imprime le contenu du fichier.\n",
        "\n",
        "Ce code est utilisé pour lire le contenu d'un fichier spécifique dans un répertoire donné et l'afficher. Il utilise la bibliothèque `pathlib` pour gérer les chemins de fichiers de manière plus robuste et portable entre différents systèmes d'exploitation."
      ],
      "metadata": {
        "id": "_hUEUoIAAhsY"
      },
      "id": "_hUEUoIAAhsY"
    },
    {
      "cell_type": "markdown",
      "id": "59f62564-cd46-4bff-bda3-c0f29a47dd9d",
      "metadata": {
        "id": "59f62564-cd46-4bff-bda3-c0f29a47dd9d"
      },
      "source": [
        "### Basic approach\n",
        "\n",
        "For basic cases we can directly ask the model to return the result.\n",
        "Let's try extracting the name of the book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdc9062-64e9-4634-855c-d06ccb5efb50",
      "metadata": {
        "tags": [],
        "id": "efdc9062-64e9-4634-855c-d06ccb5efb50"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "Given the email inside triple-backticks, please read it and analyse the contents.\n",
        "If a name of a book is mentioned, return it, otherwise return nothing.\n",
        "\n",
        "Email: ```\n",
        "{book_question_email}\n",
        "```\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that processes orders from a bookstore.\",\n",
        "    ),\n",
        "    (\"human\", query),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python dans ce texte demande de lire et analyser le contenu d'un email contenu dans des backticks (```...```), et de vérifier si un nom de livre y est mentionné. Si un nom de livre est trouvé, il doit être retourné. Sinon, la fonction doit retourner une chaîne vide ou rien.\n",
        "\n",
        "Voici une solution possible en Python pour répondre à cette question :\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "def find_book_in_email(email_content):\n",
        "    # Utilisation d'une expression régulière pour identifier un possible nom de livre\n",
        "    # On suppose qu'un nom de livre pourrait être entre guillemets ou être en majuscules.\n",
        "    match = re.search(r'\\\"(.+?)\\\"|(?:[A-Z][a-z]+\\s){1,3}[A-Z][a-z]+', email_content)\n",
        "    \n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    return None\n",
        "\n",
        "# Exemple d'email\n",
        "book_question_email = \"\"\"\n",
        "Je vous contacte au sujet de votre livre intitulé \"Les Secrets du Python\". J'ai des questions sur le chapitre 3.\n",
        "\"\"\"\n",
        "\n",
        "# Appel de la fonction\n",
        "result = find_book_in_email(book_question_email)\n",
        "\n",
        "print(result)  # Affichera le nom du livre s'il est trouvé\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- L'expression régulière utilisée dans `re.search` cherche un texte entre guillemets ou une séquence de mots avec une majuscule suivie de mots avec des minuscules (qui pourrait représenter un nom de livre).\n",
        "- Si un match est trouvé, il est retourné, sinon la fonction retourne `None`."
      ],
      "metadata": {
        "id": "nkpgRF7MAvS_"
      },
      "id": "nkpgRF7MAvS_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4742618e-25e9-441e-a6f8-b47330a0bd05",
      "metadata": {
        "tags": [],
        "id": "4742618e-25e9-441e-a6f8-b47330a0bd05"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(messages)\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce texte, la question Python concerne l'appel d'un modèle de langage (`llm`) pour traiter des messages et renvoyer le contenu de la réponse.\n",
        "\n",
        "Le code suivant montre comment un modèle d'IA pourrait être invoqué, et comment son résultat (contenu) peut être imprimé en Python. Il n'y a pas de contexte direct sur la structure de `llm`, mais cela ressemble à un modèle d'IA comme GPT utilisé via une interface API.\n",
        "\n",
        "Voici une réponse avec un exemple de code Python qui reflète la logique décrite :\n",
        "\n",
        "```python\n",
        "# Simulation d'appel à un modèle de langage pour traiter des messages\n",
        "class LLM:\n",
        "    def invoke(self, messages):\n",
        "        # Simuler une réponse basée sur le contenu du message\n",
        "        return self.Response(f\"Réponse du modèle pour le message: {messages[-1][1]}\")\n",
        "    \n",
        "    class Response:\n",
        "        def __init__(self, content):\n",
        "            self.content = content\n",
        "\n",
        "# Exemple d'utilisation\n",
        "llm = LLM()\n",
        "messages = [\n",
        "    (\"system\", \"Vous êtes un assistant utile.\"),\n",
        "    (\"human\", \"Quel est le nom de ce livre ?\"),\n",
        "]\n",
        "\n",
        "# Appel du modèle et impression de la réponse\n",
        "result = llm.invoke(messages)\n",
        "print(result.content)\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- La classe `LLM` simule un modèle de langage avec une méthode `invoke` qui prend une liste de messages et retourne une réponse simulée.\n",
        "- Le résultat de `llm.invoke(messages)` est un objet `Response`, dont l'attribut `content` contient la réponse.\n",
        "- Le contenu de la réponse est ensuite imprimé avec `print(result.content)`.\n",
        "\n",
        "Le véritable comportement dépendra de l'implémentation du modèle de langage et de l'API utilisée, mais cette structure de base illustre bien le mécanisme d'invocation et de récupération du résultat."
      ],
      "metadata": {
        "id": "gwEj65BQA9PQ"
      },
      "id": "gwEj65BQA9PQ"
    },
    {
      "cell_type": "markdown",
      "id": "e31a3407-caca-445a-bb1a-d62d40ddccd2",
      "metadata": {
        "id": "e31a3407-caca-445a-bb1a-d62d40ddccd2"
      },
      "source": [
        "### Model specific prompts\n",
        "\n",
        "While basic approach works, to achieve best results we recommend to customise your prompts for the particular model you will be using.\n",
        "In this example we are using `anthropic.claude-3`, [prompt guide for which can be found here](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design).\n",
        "\n",
        "Here is the a more optimised prompt for Claude v3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a461a9-4bad-4634-b568-a07769b1d349",
      "metadata": {
        "tags": [],
        "id": "a5a461a9-4bad-4634-b568-a07769b1d349"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Given the email provided, please read it and analyse the contents.\n",
        "If a name of a book is mentioned, return it.\n",
        "If no name is mentioned, return empty string.\n",
        "The email will be given between <email></email> XML tags.\n",
        "\n",
        "<email>\n",
        "{email}\n",
        "</email>\n",
        "\n",
        "Return the name of the book between <book></book> XML tags.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce texte, la question Python consiste à lire un email encadré par des balises XML `<email></email>`, puis à analyser son contenu pour voir si un nom de livre y est mentionné. Si un livre est mentionné, le nom doit être renvoyé entre balises `<book></book>`. Sinon, une chaîne vide doit être retournée.\n",
        "\n",
        "Voici une solution en Python pour accomplir cette tâche :\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "def find_book_in_email(email_content):\n",
        "    # Extraction du contenu entre les balises <email></email>\n",
        "    email_match = re.search(r'<email>(.*?)</email>', email_content, re.DOTALL)\n",
        "    \n",
        "    if email_match:\n",
        "        email_text = email_match.group(1)\n",
        "        \n",
        "        # Recherche d'un nom de livre potentiel entre guillemets\n",
        "        book_match = re.search(r'\\\"(.+?)\\\"', email_text)\n",
        "        \n",
        "        if book_match:\n",
        "            # Retourne le nom du livre entre balises <book></book>\n",
        "            return f\"<book>{book_match.group(1)}</book>\"\n",
        "    \n",
        "    # Si aucun livre n'est trouvé, retourne une chaîne vide\n",
        "    return \"<book></book>\"\n",
        "\n",
        "# Exemple d'email\n",
        "email = \"\"\"\n",
        "<email>\n",
        "Je voudrais vous poser une question sur le livre \"Apprendre Python en 30 jours\". Est-il encore disponible ?\n",
        "</email>\n",
        "\"\"\"\n",
        "\n",
        "# Appel de la fonction\n",
        "result = find_book_in_email(email)\n",
        "\n",
        "print(result)  # Affichera le nom du livre s'il est trouvé, ou une chaîne vide sinon\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- On utilise `re.search` pour extraire le contenu entre les balises `<email></email>`.\n",
        "- Une deuxième recherche (`re.search`) est utilisée pour trouver un texte entre guillemets, qui pourrait représenter un nom de livre.\n",
        "- Si un livre est trouvé, il est encapsulé entre les balises `<book></book>`.\n",
        "- Si aucun livre n'est trouvé, une balise vide `<book></book>` est retournée."
      ],
      "metadata": {
        "id": "ARNvToOsBOjZ"
      },
      "id": "ARNvToOsBOjZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5142cff9-c2d3-451e-8d21-06ce8538adb5",
      "metadata": {
        "tags": [],
        "id": "5142cff9-c2d3-451e-8d21-06ce8538adb5"
      },
      "outputs": [],
      "source": [
        "query = prompt.format(email=book_question_email)\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that processes orders from a bookstore.\",\n",
        "    ),\n",
        "    (\"human\", query),\n",
        "]\n",
        "result = llm.invoke(messages).content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici concerne l'envoi d'une requête formatée à un modèle de langage (`llm`) pour analyser le contenu d'un email et renvoyer un résultat. L'email est formaté dans une variable `query`, puis inséré dans une structure de message envoyée au modèle.\n",
        "\n",
        "Voici une solution qui montre comment cela pourrait fonctionner dans un scénario Python typique, en utilisant un modèle de langage fictif `llm` pour simuler l'appel :\n",
        "\n",
        "```python\n",
        "class LLM:\n",
        "    def invoke(self, messages):\n",
        "        # Simulation de la réponse du modèle\n",
        "        return self.Response(f\"Le livre trouvé est : 'Python pour les débutants'.\")\n",
        "    \n",
        "    class Response:\n",
        "        def __init__(self, content):\n",
        "            self.content = content\n",
        "\n",
        "# Initialisation du modèle de langage\n",
        "llm = LLM()\n",
        "\n",
        "# Formatage de la requête avec l'email\n",
        "book_question_email = \"\"\"\n",
        "Je suis intéressé par le livre 'Python pour les débutants'. Pouvez-vous m'en dire plus ?\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "Given the email provided, please read it and analyse the contents.\n",
        "If a name of a book is mentioned, return it.\n",
        "If no name is mentioned, return empty string.\n",
        "The email will be given between <email></email> XML tags.\n",
        "\n",
        "<email>\n",
        "{email}\n",
        "</email>\n",
        "\n",
        "Return the name of the book between <book></book> XML tags.\n",
        "\"\"\"\n",
        "\n",
        "# Formatage de la requête\n",
        "query = prompt.format(email=book_question_email)\n",
        "\n",
        "# Création des messages à envoyer au modèle\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful assistant that processes orders from a bookstore.\"),\n",
        "    (\"human\", query),\n",
        "]\n",
        "\n",
        "# Invocation du modèle et récupération du résultat\n",
        "result = llm.invoke(messages).content\n",
        "\n",
        "# Affichage du résultat\n",
        "print(result)\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- `LLM` est une classe simulant le modèle de langage. Elle contient une méthode `invoke` qui reçoit des messages et renvoie une réponse simulée.\n",
        "- Le `prompt` contient la logique pour formater un email dans une structure XML, où le contenu de l'email est inséré à l'aide de `format()`.\n",
        "- `query` est le texte final envoyé au modèle après le formatage avec le contenu réel de l'email.\n",
        "- `llm.invoke(messages)` appelle le modèle avec les messages et renvoie un objet `Response` contenant la réponse, qui est ensuite imprimée.\n",
        "\n",
        "Dans un vrai environnement, le modèle de langage renverrait une analyse basée sur le contenu de l'email."
      ],
      "metadata": {
        "id": "gKMXMWUkBafY"
      },
      "id": "gKMXMWUkBafY"
    },
    {
      "cell_type": "markdown",
      "id": "e87ee5ab-33d9-4def-a462-8e5992032bd0",
      "metadata": {
        "id": "e87ee5ab-33d9-4def-a462-8e5992032bd0"
      },
      "source": [
        "To extract results easier, we can use a helper function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa9d2d0-2bc8-465c-b89b-73b2fd76d4b2",
      "metadata": {
        "tags": [],
        "id": "bfa9d2d0-2bc8-465c-b89b-73b2fd76d4b2"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_by_tag(response: str, tag: str, extract_all=False) -> str | list[str] | None:\n",
        "    soup = BeautifulSoup(response)\n",
        "    results = soup.find_all(tag)\n",
        "    if not results:\n",
        "        return\n",
        "\n",
        "    texts = [res.get_text() for res in results]\n",
        "    if extract_all:\n",
        "        return texts\n",
        "    return texts[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici porte sur l'extraction de texte à partir de balises spécifiques dans une réponse HTML à l'aide de BeautifulSoup. Le code fourni définit une fonction `extract_by_tag` qui accepte trois paramètres : la réponse HTML sous forme de chaîne (`response`), le nom de la balise (`tag`) à extraire, et un booléen (`extract_all`) qui détermine s'il faut extraire tous les éléments correspondants ou seulement le dernier.\n",
        "\n",
        "Voici une explication de ce que fait ce code et comment l'améliorer :\n",
        "\n",
        "1. **Analyse de la structure :**\n",
        "   - `BeautifulSoup(response)` : Analyse la réponse HTML pour permettre une manipulation facile des balises.\n",
        "   - `soup.find_all(tag)` : Trouve toutes les occurrences de la balise spécifiée dans le document.\n",
        "   - Si `extract_all` est vrai, la fonction retourne une liste de textes correspondant à chaque balise trouvée.\n",
        "   - Sinon, elle retourne uniquement le texte de la dernière balise trouvée.\n",
        "\n",
        "2. **Amélioration** : Pour plus de robustesse, il pourrait être utile de spécifier le parser utilisé par BeautifulSoup (comme `html.parser`) et de traiter correctement les valeurs `None`.\n",
        "\n",
        "Voici une version améliorée du code :\n",
        "\n",
        "```python\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Union, List, Optional\n",
        "\n",
        "def extract_by_tag(response: str, tag: str, extract_all: bool = False) -> Union[str, List[str], None]:\n",
        "    # Analyse du contenu HTML avec le parser HTML standard\n",
        "    soup = BeautifulSoup(response, 'html.parser')\n",
        "    \n",
        "    # Recherche de toutes les balises correspondant au tag spécifié\n",
        "    results = soup.find_all(tag)\n",
        "    \n",
        "    if not results:\n",
        "        return None  # Retourne None si aucune balise n'est trouvée\n",
        "        \n",
        "    # Extrait le texte de chaque balise trouvée\n",
        "    texts = [res.get_text() for res in results]\n",
        "    \n",
        "    # Retourne tous les textes si extract_all est True, sinon retourne seulement le dernier texte\n",
        "    if extract_all:\n",
        "        return texts\n",
        "    return texts[-1] if texts else None\n",
        "\n",
        "# Exemple d'utilisation\n",
        "response_html = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <p>Premier paragraphe</p>\n",
        "    <p>Deuxième paragraphe</p>\n",
        "    <p>Dernier paragraphe</p>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Extraction du dernier paragraphe\n",
        "print(extract_by_tag(response_html, 'p'))\n",
        "\n",
        "# Extraction de tous les paragraphes\n",
        "print(extract_by_tag(response_html, 'p', extract_all=True))\n",
        "```\n",
        "\n",
        "### Explication des améliorations :\n",
        "- **Parser HTML explicite** : `'html.parser'` est spécifié pour que BeautifulSoup sache quel parser utiliser.\n",
        "- **Utilisation de `Optional` et `Union` dans les annotations de type** pour mieux documenter le fait que la fonction peut renvoyer une chaîne, une liste de chaînes ou `None`.\n",
        "- **Robustesse** : La fonction retourne `None` si aucune balise n'est trouvée, pour gérer les cas où le tag est absent du document."
      ],
      "metadata": {
        "id": "Bgu__9OLBt2h"
      },
      "id": "Bgu__9OLBt2h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef7b280-71be-41ad-9f21-8c87d09226ae",
      "metadata": {
        "tags": [],
        "id": "fef7b280-71be-41ad-9f21-8c87d09226ae"
      },
      "outputs": [],
      "source": [
        "extract_by_tag(result, \"book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici concerne l'utilisation de la fonction `extract_by_tag` pour extraire du texte d'une balise `<book>` dans la variable `result`. La fonction a probablement été définie pour prendre un contenu HTML (ou similaire) et en extraire le texte se trouvant à l'intérieur d'une balise donnée, ici `\"book\"`.\n",
        "\n",
        "Si nous utilisons la fonction définie précédemment, voici comment vous pourriez l'appliquer à l'extraction du contenu à l'intérieur de la balise `<book>` de la variable `result` :\n",
        "\n",
        "### Exemple d'utilisation :\n",
        "\n",
        "```python\n",
        "# Supposons que 'result' contient le HTML ou XML retourné\n",
        "result = \"\"\"\n",
        "<response>\n",
        "    <book>Apprendre Python</book>\n",
        "    <book>Python Avancé</book>\n",
        "</response>\n",
        "\"\"\"\n",
        "\n",
        "# Extraction de la dernière balise <book>\n",
        "book_name = extract_by_tag(result, \"book\")\n",
        "\n",
        "# Affichage du résultat\n",
        "print(book_name)  # Affichera 'Python Avancé'\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- `extract_by_tag(result, \"book\")` appelle la fonction pour chercher toutes les balises `<book>` dans la chaîne `result`.\n",
        "- Si plusieurs balises `<book>` existent, la fonction (avec `extract_all=False` par défaut) renvoie uniquement le texte de la dernière balise trouvée.\n",
        "- Dans cet exemple, cela retournerait \"Python Avancé\" car c'est le dernier livre dans la balise `<book>`.\n",
        "\n",
        "Si vous vouliez extraire **tous** les livres, vous pouvez passer l'argument `extract_all=True` :\n",
        "\n",
        "```python\n",
        "# Extraction de toutes les balises <book>\n",
        "all_books = extract_by_tag(result, \"book\", extract_all=True)\n",
        "\n",
        "# Affichage de tous les résultats\n",
        "print(all_books)  # Affichera ['Apprendre Python', 'Python Avancé']\n",
        "```"
      ],
      "metadata": {
        "id": "2pkR_N0BCY5P"
      },
      "id": "2pkR_N0BCY5P"
    },
    {
      "cell_type": "markdown",
      "id": "f19454e6-22cd-41ee-888c-39801cc72c74",
      "metadata": {
        "id": "f19454e6-22cd-41ee-888c-39801cc72c74"
      },
      "source": [
        "We can check that our model doesn't return arbitrary results when no appropriate information is given (also know as 'hallucination'), by running our prompt on other emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fd1343-9b4b-4efd-846f-1312af18e15c",
      "metadata": {
        "tags": [],
        "id": "35fd1343-9b4b-4efd-846f-1312af18e15c"
      },
      "outputs": [],
      "source": [
        "with open(emails_dir / \"01_return.txt\") as f:\n",
        "    return_email = f.read()\n",
        "\n",
        "print(return_email)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici consiste à lire le contenu d'un fichier texte nommé `\"01_return.txt\"` situé dans un répertoire `emails_dir` et à afficher ce contenu. Le fichier est ouvert avec `open()`, lu entièrement avec `f.read()`, puis imprimé avec `print()`.\n",
        "\n",
        "Voici une explication et un exemple complet de cette opération en Python :\n",
        "\n",
        "### Explication :\n",
        "1. **Chemin du fichier** : `emails_dir / \"01_return.txt\"` indique que le fichier se trouve dans le répertoire `emails_dir`. Cela suggère que `emails_dir` est un objet de type `Path` (probablement de la bibliothèque `pathlib`).\n",
        "2. **Lecture du fichier** : Le fichier est ouvert en mode lecture (`'r'` par défaut) et son contenu est lu avec `f.read()`.\n",
        "3. **Affichage du contenu** : Le contenu est ensuite affiché avec `print(return_email)`.\n",
        "\n",
        "### Exemple complet avec la gestion de fichiers en Python :\n",
        "\n",
        "```python\n",
        "from pathlib import Path\n",
        "\n",
        "# Chemin du répertoire contenant les emails\n",
        "emails_dir = Path(\"/chemin/vers/emails\")\n",
        "\n",
        "# Ouverture et lecture du fichier \"01_return.txt\"\n",
        "with open(emails_dir / \"01_return.txt\") as f:\n",
        "    return_email = f.read()\n",
        "\n",
        "# Affichage du contenu du fichier\n",
        "print(return_email)\n",
        "```\n",
        "\n",
        "### Explication supplémentaire :\n",
        "- **`Path` de `pathlib`** : Utilisé pour manipuler les chemins de fichiers de manière portable.\n",
        "- **`with open(...)`** : Le bloc `with` garantit que le fichier est automatiquement fermé après avoir été lu, même en cas d'erreur.\n",
        "- **`f.read()`** : Lit tout le contenu du fichier sous forme de chaîne.\n",
        "\n",
        "Cela va afficher le texte contenu dans le fichier `\"01_return.txt\"`."
      ],
      "metadata": {
        "id": "79o1freLCljY"
      },
      "id": "79o1freLCljY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec8a1b2-beb4-4ddf-9935-1fc7a3b08729",
      "metadata": {
        "tags": [],
        "id": "4ec8a1b2-beb4-4ddf-9935-1fc7a3b08729"
      },
      "outputs": [],
      "source": [
        "query = prompt.format(email=return_email)\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that processes orders from a bookstore.\",\n",
        "    ),\n",
        "    (\"human\", query),\n",
        "]\n",
        "result = llm.invoke(query).content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici porte sur l'invocation d'un modèle de langage (`llm`) pour traiter un message formaté à partir d'un email contenu dans la variable `return_email`. Le processus consiste à formater le message en utilisant une structure de `prompt`, puis à envoyer ce message au modèle pour obtenir une réponse.\n",
        "\n",
        "Voici une explication détaillée du processus, ainsi qu'un exemple de code montrant comment cela pourrait fonctionner :\n",
        "\n",
        "### Explication :\n",
        "1. **Formatage de la requête** : `query = prompt.format(email=return_email)` utilise la méthode `format` pour insérer le contenu de l'email (`return_email`) dans un `prompt` prédéfini, où le champ `{email}` est remplacé par l'email réel.\n",
        "2. **Messages** : Une liste de messages est créée. Le premier message, `\"system\"`, donne des instructions au modèle, tandis que le second, `\"human\"`, contient la requête formatée (`query`).\n",
        "3. **Invocation du modèle** : `llm.invoke(query)` est une invocation du modèle de langage (`llm`), qui renvoie un objet contenant le résultat dans l'attribut `content`.\n",
        "4. **Affichage du résultat** : Le contenu de la réponse (`result.content`) est ensuite affiché avec `print()`.\n",
        "\n",
        "### Exemple de code Python :\n",
        "\n",
        "```python\n",
        "# Supposons que 'llm' soit un modèle de langage déjà initialisé\n",
        "class LLM:\n",
        "    def invoke(self, query):\n",
        "        # Simule la réponse du modèle\n",
        "        return self.Response(f\"Le résultat pour l'email est : {query}\")\n",
        "    \n",
        "    class Response:\n",
        "        def __init__(self, content):\n",
        "            self.content = content\n",
        "\n",
        "# Initialisation du modèle de langage\n",
        "llm = LLM()\n",
        "\n",
        "# Exemple de contenu du fichier email\n",
        "return_email = \"\"\"\n",
        "Cher libraire,\n",
        "Je voudrais retourner le livre \"Python Avancé\". Puis-je avoir des instructions sur le processus de retour ?\n",
        "Merci.\n",
        "\"\"\"\n",
        "\n",
        "# Formatage du prompt\n",
        "prompt = \"\"\"\n",
        "Given the email provided, please read it and analyse the contents.\n",
        "If a name of a book is mentioned, return it.\n",
        "If no name is mentioned, return empty string.\n",
        "The email will be given between <email></email> XML tags.\n",
        "\n",
        "<email>\n",
        "{email}\n",
        "</email>\n",
        "\n",
        "Return the name of the book between <book></book> XML tags.\n",
        "\"\"\"\n",
        "\n",
        "# Formatage de la requête\n",
        "query = prompt.format(email=return_email)\n",
        "\n",
        "# Création des messages\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful assistant that processes orders from a bookstore.\"),\n",
        "    (\"human\", query),\n",
        "]\n",
        "\n",
        "# Invocation du modèle et récupération du résultat\n",
        "result = llm.invoke(query).content\n",
        "\n",
        "# Affichage du résultat\n",
        "print(result)\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "- Le modèle `LLM` est simulé pour répondre à la requête formatée. Dans un vrai scénario, `llm.invoke()` ferait appel à une API de modèle de langage pour analyser et traiter la requête.\n",
        "- Le contenu de l'email est inséré dans le `prompt` à l'endroit de `{email}`, et le modèle analyse cette requête.\n",
        "- Le résultat du modèle est récupéré et affiché avec `print(result)`.\n",
        "\n",
        "Ce code montre comment la chaîne de traitement fonctionne pour un modèle de langage interactif dans un contexte de gestion des commandes d'une librairie."
      ],
      "metadata": {
        "id": "5SdXnWmICrCv"
      },
      "id": "5SdXnWmICrCv"
    },
    {
      "cell_type": "markdown",
      "id": "d154c270-41dc-4e58-bca2-f9fe5d021223",
      "metadata": {
        "id": "d154c270-41dc-4e58-bca2-f9fe5d021223"
      },
      "source": [
        "Using tags also allows us to extract multiple pieces of information at the same time and makes extraction much easier.\n",
        "In the following prompt we will extract not just the book name, but any questions, requests and customer name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5b5c9b-b0c0-427d-a7fb-005253e9bbb3",
      "metadata": {
        "tags": [],
        "id": "ea5b5c9b-b0c0-427d-a7fb-005253e9bbb3"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Human: Given email provided , please read it and analyse the contents.\n",
        "\n",
        "Please extract the following information from the email:\n",
        "- Any questions the customer is asking, return it inside <questions></questions> XML tags.\n",
        "- The customer full name, return it inside <name></name> XML tags.\n",
        "- Any book names the customer mentions, return it inside <books></books> XML tags.\n",
        "\n",
        "If a particular bit of information is not present, return an empty string.\n",
        "Make sure that each question can be understoon by itself, incorporate context if requred.\n",
        "Each returned question should be concise, remove extra information if possible.\n",
        "The email will be given between <email></email> XML tags.\n",
        "\n",
        "<email>\n",
        "{email}\n",
        "</email>\n",
        "\n",
        "Return each question inside <question></question> XML tags.\n",
        "Return the name of each book inside <book></book> XML tags.\n",
        "\n",
        "Assistant:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac605eb5-2483-46ed-a205-6932051c8d2b",
      "metadata": {
        "tags": [],
        "id": "ac605eb5-2483-46ed-a205-6932051c8d2b"
      },
      "outputs": [],
      "source": [
        "query = prompt.format(email=book_question_email)\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that processes orders from a bookstore.\",\n",
        "    ),\n",
        "    (\"human\", query),\n",
        "]\n",
        "result = llm.invoke(query).content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question Python ici consiste à formater une requête en insérant le contenu de l'email dans un modèle de langage, à envoyer cette requête via une invocation du modèle (`llm.invoke(query)`), puis à afficher le résultat. Le processus commence par la construction d'un message formaté à l'aide de `prompt.format()` et continue avec l'interaction avec un assistant (système) pour traiter une commande.\n",
        "\n",
        "Voici un exemple de code illustrant cela, avec un modèle de langage fictif pour simuler la réponse.\n",
        "\n",
        "### Exemple complet :\n",
        "\n",
        "```python\n",
        "# Supposons que 'llm' soit un modèle de langage déjà initialisé\n",
        "class LLM:\n",
        "    def invoke(self, query):\n",
        "        # Simulation de la réponse du modèle à partir de la requête\n",
        "        return self.Response(f\"Voici le livre que vous cherchez : 'Python pour les débutants'. Requête : {query}\")\n",
        "    \n",
        "    class Response:\n",
        "        def __init__(self, content):\n",
        "            self.content = content\n",
        "\n",
        "# Initialisation du modèle fictif\n",
        "llm = LLM()\n",
        "\n",
        "# Exemple de contenu de l'email contenant une question sur un livre\n",
        "book_question_email = \"\"\"\n",
        "Bonjour, je voudrais avoir des informations sur le livre 'Python pour les débutants'.\n",
        "Pouvez-vous me fournir plus de détails ?\n",
        "\"\"\"\n",
        "\n",
        "# Prompt avec un espace pour insérer l'email\n",
        "prompt = \"\"\"\n",
        "Given the email provided, please read it and analyse the contents.\n",
        "If a name of a book is mentioned, return it.\n",
        "If no name is mentioned, return empty string.\n",
        "The email will be given between <email></email> XML tags.\n",
        "\n",
        "<email>\n",
        "{email}\n",
        "</email>\n",
        "\n",
        "Return the name of the book between <book></book> XML tags.\n",
        "\"\"\"\n",
        "\n",
        "# Formatage de la requête\n",
        "query = prompt.format(email=book_question_email)\n",
        "\n",
        "# Création des messages à envoyer au modèle\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful assistant that processes orders from a bookstore.\"),\n",
        "    (\"human\", query),\n",
        "]\n",
        "\n",
        "# Invocation du modèle et récupération du résultat\n",
        "result = llm.invoke(query).content\n",
        "\n",
        "# Affichage du résultat\n",
        "print(result)\n",
        "```\n",
        "\n",
        "### Explication :\n",
        "1. **`prompt.format(email=book_question_email)`** : Formate le `prompt` en insérant le contenu de l'email (`book_question_email`) dans la place réservée `{email}`.\n",
        "2. **`messages`** : Une liste contenant les rôles du système et de l'humain, où le message de l'humain est la requête formatée (`query`).\n",
        "3. **`llm.invoke(query)`** : Le modèle de langage reçoit la requête formatée et renvoie un résultat sous forme d'une chaîne `result.content`.\n",
        "4. **Affichage** : Le résultat est affiché avec `print(result)`.\n",
        "\n",
        "Cela simule un assistant qui traite une commande pour un livre mentionné dans un email."
      ],
      "metadata": {
        "id": "fLhRmmL1DEAu"
      },
      "id": "fLhRmmL1DEAu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7cc2cb-8036-44a5-9fb6-db2172f9b601",
      "metadata": {
        "tags": [],
        "id": "8a7cc2cb-8036-44a5-9fb6-db2172f9b601"
      },
      "outputs": [],
      "source": [
        "extract_by_tag(result, \"question\", extract_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5617e0d-0923-45b6-8e91-03748ad76d31",
      "metadata": {
        "tags": [],
        "id": "f5617e0d-0923-45b6-8e91-03748ad76d31"
      },
      "outputs": [],
      "source": [
        "extract_by_tag(result, \"name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66852eb2-97a2-4041-a76f-3fb03e1aaef5",
      "metadata": {
        "tags": [],
        "id": "66852eb2-97a2-4041-a76f-3fb03e1aaef5"
      },
      "outputs": [],
      "source": [
        "extract_by_tag(result, \"book\", extract_all=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d830e149-5c89-4f50-9833-b499ee70f3f3",
      "metadata": {
        "id": "d830e149-5c89-4f50-9833-b499ee70f3f3"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Entity extraction is a powerful technique using which you can extract arbitrary data using plain text descriptions.\n",
        "\n",
        "This is particularly useful when you need to extract specific data which doesn't have clear structure. In such cases regex and other traditional extraction techniques can be very difficult to implement.\n",
        "\n",
        "### Take aways\n",
        "- Adapt this notebook to experiment with different models available through Amazon Bedrock such as Amazon Titan and AI21 Labs Jurassic models.\n",
        "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
        "- Apply different prompt engineering principles to get better outputs. Refer to the prompt guide for your chosen model for recommendations, e.g. [here is the prompt guide for Claude](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95bf2beb-c2d1-4aef-acb4-83eec89569e2",
      "metadata": {
        "id": "95bf2beb-c2d1-4aef-acb4-83eec89569e2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 57,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.trn1.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 58,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1.32xlarge",
        "vcpuNum": 128
      },
      {
        "_defaultOrder": 59,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1n.32xlarge",
        "vcpuNum": 128
      }
    ],
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}